import os.path as osp

import mmcv
import numpy as np
import os
from .custom import CustomDataset
import cv2
import json
import os.path as osp

import mmcv
import numpy as np
from mmcv.parallel import DataContainer as DC
from torch.utils.data import Dataset
import cv2
from .transforms import (ImageTransform, BboxTransform, MaskTransform,
                         SegMapTransform, Numpy2Tensor)
from .utils import to_tensor, random_scale
from .extra_aug import ExtraAugmentation
from .registry import DATASETS

@DATASETS.register_module
class VisDroneDataset(CustomDataset):
    CLASSES = [ 'pedestrian',
                     'people', 'bicycle', 'car', 'van', 'truck', 'tricycle',
                     'awning-tricycle', 'bus', 'motor',]# 12 in total
    def __init__(self,ann_file,
                     img_prefix,
                     img_scale,
                     img_norm_cfg,
                     multiscale_mode='value',
                     size_divisor=None,
                     proposal_file=None,
                     num_max_proposals=1000,
                     flip_ratio=0,
                     with_mask=True,
                     with_crowd=True,
                     with_label=True,
                     with_semantic_seg=False,
                     seg_prefix=None,
                     seg_scale_factor=1,
                     extra_aug=None,
                     resize_keep_ratio=True,
                     test_mode=False,
                     slide_test = None,  **kwargs):
        super(VisDroneDataset, self).__init__(ann_file=ann_file,
                                                     img_prefix=img_prefix,
                                                     img_scale=img_scale,
                                                     img_norm_cfg=img_norm_cfg,
                                                     multiscale_mode=multiscale_mode,
                                                     size_divisor=size_divisor,
                                                     proposal_file=proposal_file,
                                                     num_max_proposals=num_max_proposals,
                                                     flip_ratio=flip_ratio,
                                                     with_mask=with_mask,
                                                     with_crowd=with_crowd,
                                                     with_label=with_label,
                                                     with_semantic_seg=with_semantic_seg,
                                                     seg_prefix=seg_prefix,
                                                     seg_scale_factor=seg_scale_factor,
                                                     extra_aug=extra_aug,
                                                     resize_keep_ratio=resize_keep_ratio,
                                                     test_mode=test_mode,
                                                     **kwargs)
        self.cat2label = {cat: i + 1 for i, cat in enumerate(self.CLASSES)}
        self.slide_test = slide_test

    def load_annotations(self, ann_file):
        """
        for the visdrone, anno_file is pre generated by a script.
        """
        if not os.path.exists(ann_file):
            root = '/'.join(ann_file.split('/')[:-1])
            img_root = os.path.join(root,'images')
            #print(img_root)
            imgs = os.listdir(img_root)
            imgs.sort()

            img_infos = []
            result = dict()
            with open(os.path.join(root, 'img_size_anno.json'), 'w') as dst_file:
                json.dump(result, dst_file)
            for img_file in imgs:
                img_id = img_file.split('.')[0]
                filename = 'images'+ '/{}.jpg'.format(img_id)
                img_path = osp.join(img_root, '{}.jpg'.format(img_id))
                print(img_path)
                img = cv2.imread(img_path)
                h, w, c = img.shape
                width = int(w)
                height = int(h)
                img_infos.append(
                    dict(id=img_id, filename=filename, width=width,
                         height=height))
            result['img_infos'] = img_infos
            with open(os.path.join(root, 'img_size_anno.json'), 'w') as dst_file:
                json.dump(result, dst_file)
            print(len(img_infos))
            return img_infos
        else:
            with open(ann_file,'r') as fobj:
                img_infos_dict = json.load(fobj)
            print(len(img_infos_dict['img_infos']))

            return img_infos_dict['img_infos']

    def get_ann_info(self, idx):
        img_id = self.img_infos[idx]['id']
        anno_path = osp.join(self.img_prefix, 'annotations',
                            '{}.txt'.format(img_id))
        #tree = ET.parse(xml_path)
        #root = tree.getroot()
        bboxes = []
        labels = []
        bboxes_ignore = []
        labels_ignore = []
        with open(anno_path,'r') as anno:
            all_info = anno.readlines()

            for item in all_info:
                values_str = item.split(',')#list()
                bbox_left,bbox_top,bbox_width,bbox_height,score,object_category,\
                truncation,occulusion = int(values_str[0]),int(values_str[1]),\
                int(values_str[2]),int(values_str[3]),float(values_str[4]),int(values_str[5]),\
                int(values_str[6]),int(values_str[7])
                label = object_category
                #if not self.test_mode:#train set and val/test set , has different label annotation
                if label == 0 or label == 11:
                    continue
                else:
                    label = label # 标注从1 开始
                #if self.test_mode:
                #    label = label+1
                if bbox_height<=0 or bbox_width<=0:
                    continue
                if bbox_height / bbox_width > 6.0 or bbox_width / bbox_height > 6.0:
                    continue
                # xmin  ymin  xmax  ymax
                bbox = [bbox_left,bbox_top,bbox_left+bbox_width-1,bbox_top+bbox_height-1]
                # 截断的 过于模糊的都会可能会造成loss波动太大， 去掉
                if self.test_mode:
                    if score==1:
                        bboxes.append(bbox)
                        labels.append(label)
                    else:
                        bboxes_ignore.append(bbox)
                        labels_ignore.append(label)
                else:
                    if score==1: #and truncation==0 and (occulusion==0 or occulusion==1):
                        bboxes.append(bbox)
                        labels.append(label)
                    elif score==0:
                        bboxes_ignore.append(bbox)
                        labels_ignore.append(label)
                    else:
                        raise IndexError
        assert len(labels) + len(labels_ignore) == len(bboxes) + len(bboxes_ignore),'label is not equal to bboxes'
        if not bboxes:
            bboxes = np.zeros((0, 4))
            labels = np.zeros((0, ))
        else:
            bboxes = np.array(bboxes, ndmin=2)#坐标是否需要减一？？
            labels = np.array(labels)
        if not bboxes_ignore:
            bboxes_ignore = np.zeros((0, 4))
            labels_ignore = np.zeros((0, ))
        else:
            bboxes_ignore = np.array(bboxes_ignore, ndmin=2) #坐标是否需要减一？？
            labels_ignore = np.array(labels_ignore)
        #assert bboxes.shape[0]>0,print(bboxes.shape)
        ann = dict(
            bboxes=bboxes.astype(np.float32),
            labels=labels.astype(np.int64),
            bboxes_ignore=bboxes_ignore.astype(np.float32),
            labels_ignore=labels_ignore.astype(np.int64))
        #visualization
        vis_flag = False
        if vis_flag:
            filename = 'images/{}.jpg'.format(img_id)
            img_path = osp.join(self.img_prefix, filename)
            img = cv2.imread(img_path)
            bboxes_sum = np.concatenate([bboxes,bboxes_ignore],axis=0).astype(np.float32)
            labels_sum = np.concatenate([labels,labels_ignore],axis=0).astype(np.int64)
            mmcv.imshow_det_bboxes(img,bboxes_sum,labels_sum,self.CLASSES,show=False,out_file='/home/share2/VisDrone2019/TASK1/visualization/'+img_id+'.jpg')

        return ann
    def prepare_test_img(self, idx):
        """Prepare an image for testing (multi-scale and flipping)"""
        img_info = self.img_infos[idx]
        img = mmcv.imread(osp.join(self.img_prefix, img_info['filename']))
        if self.proposals is not None:
            proposal = self.proposals[idx][:self.num_max_proposals]
            if not (proposal.shape[1] == 4 or proposal.shape[1] == 5):
                raise AssertionError(
                    'proposals should have shapes (n, 4) or (n, 5), '
                    'but found {}'.format(proposal.shape))
        else:
            proposal = None

        if self.slide_test is None:
            def prepare_single(img, scale, flip, proposal=None):
                _img, img_shape, pad_shape, scale_factor = self.img_transform(
                    img, scale, flip, keep_ratio=self.resize_keep_ratio)
                _img = to_tensor(_img)
                _img_meta = dict(
                    ori_shape=(img_info['height'], img_info['width'], 3),
                    img_shape=img_shape,
                    pad_shape=pad_shape,
                    scale_factor=scale_factor,
                    lefttop=(0,0), # for unified wiht slide win test mode
                    flip=flip)
                if proposal is not None:
                    if proposal.shape[1] == 5:
                        score = proposal[:, 4, None]
                        proposal = proposal[:, :4]
                    else:
                        score = None
                    _proposal = self.bbox_transform(proposal, img_shape,
                                                    scale_factor, flip)
                    _proposal = np.hstack(
                        [_proposal, score]) if score is not None else _proposal
                    _proposal = to_tensor(_proposal)
                else:
                    _proposal = None
                return _img, _img_meta, _proposal

            imgs = []
            img_metas = []
            proposals = []
            for scale in self.img_scales:
                _img, _img_meta, _proposal = prepare_single(
                    img, scale, False, proposal)
                imgs.append(_img)
                img_metas.append(DC(_img_meta, cpu_only=True))
                proposals.append(_proposal)
                if self.flip_ratio > 0:
                    _img, _img_meta, _proposal = prepare_single(
                        img, scale, True, proposal)
                    imgs.append(_img)
                    img_metas.append(DC(_img_meta, cpu_only=True))
                    proposals.append(_proposal)
            data = dict(img=imgs, img_meta=img_metas)
            if self.proposals is not None:
                data['proposals'] = proposals
            return data

        else:
            self.winsize = self.slide_test['winsize']
            self.overlapratio = self.slide_test['overlapratio']
            def prepare_single(img, scale, flip, proposal=None, lefttop=(0, 0)):
                _img, img_shape, pad_shape, scale_factor = self.img_transform(
                    img, scale, flip, keep_ratio=self.resize_keep_ratio)
                _img = to_tensor(_img)
                _img_meta = dict(
                    ori_shape=(img_info['height'], img_info['width'], 3),
                    img_shape=img_shape,
                    pad_shape=pad_shape,
                    scale_factor=scale_factor,
                    lefttop=lefttop,
                    flip=flip)
                if proposal is not None:
                    if proposal.shape[1] == 5:
                        score = proposal[:, 4, None]
                        proposal = proposal[:, :4]
                    else:
                        score = None
                    _proposal = self.bbox_transform(proposal, img_shape,
                                                    scale_factor, flip)
                    _proposal = np.hstack(
                        [_proposal, score]) if score is not None else _proposal
                    _proposal = to_tensor(_proposal)
                else:
                    _proposal = None
                return _img, _img_meta, _proposal

            imgs = []
            img_metas = []
            proposals = []
            for scale in self.img_scales:
                h, w, _ = img.shape

                win_h, win_w = self.winsize[0] * h, self.winsize[1] * w
                overlapratio = self.overlapratio
                # get overlap = max edge
                overlap = max(win_h * overlapratio, win_w * overlapratio)

                assert win_h / win_w < 3 and win_w / win_h > 1 / 3
                # get all wins
                interval_w = win_w - overlap
                interval_h = win_h - overlap

                wins_lefttop = []

                row_idx = 0
                while ((row_idx * interval_h + win_h) < h):
                    col_idx = 0
                    while ((col_idx * interval_w + win_w) < w):
                        wins_lefttop.append((col_idx * interval_w, row_idx * interval_h))
                        col_idx += 1
                    wins_lefttop.append((w - win_w, row_idx * interval_h))
                    row_idx += 1
                col_idx = 0
                while ((col_idx * interval_w + win_w) < w):
                    wins_lefttop.append((col_idx * interval_w, h - win_h))
                    col_idx += 1
                wins_lefttop.append((w - win_w, h - win_h))

                num_wins = len(wins_lefttop)

                # all windows for some scale
                for ii in range(num_wins + 1):
                    # when ii == num_wins , full img is obtained, this is used to deal with a very large object
                    win_img = img
                    left, top = 0, 0
                    if ii < num_wins:  # slide window
                        left, top = wins_lefttop[ii]
                        patch = np.array((int(left), int(top), int(left + win_w),
                                          int(top + win_h)))
                        win_img = img[patch[1]:patch[3], patch[0]:patch[2]]

                    _img, _img_meta, _proposal = prepare_single(
                        win_img, scale, False, proposal, (int(left), int(top)))
                    imgs.append(_img)
                    img_metas.append(DC(_img_meta, cpu_only=True))
                    proposals.append(_proposal)
                    if self.flip_ratio > 0:
                        _img, _img_meta, _proposal = prepare_single(
                            img, scale, True, proposal)
                        imgs.append(_img)
                        img_metas.append(DC(_img_meta, cpu_only=True))
                        proposals.append(_proposal)
            data = dict(img=imgs, img_meta=img_metas)
            if self.proposals is not None:
                data['proposals'] = proposals
            return data

